{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFCx6jZU3m11"
   },
   "source": [
    "<!-- Banner Image -->\n",
    "<img src=\"https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brevdevnotebooks.png\" width=\"100%\">\n",
    "\n",
    "<!-- Links -->\n",
    "<center>\n",
    "  <a href=\"https://console.brev.dev\" style=\"color: #06b6d4;\">Console</a> \n",
    "  <a href=\"https://brev.dev\" style=\"color: #06b6d4;\">Docs</a> \n",
    "  <a href=\"/\" style=\"color: #06b6d4;\">Templates</a> \n",
    "  <a href=\"https://discord.gg/NVDyv7TUgJ\" style=\"color: #06b6d4;\">Discord</a>\n",
    "</center>\n",
    "\n",
    "# Fine-tuning Mistral on your own data \n",
    "\n",
    "Welcome!\n",
    "\n",
    "In this notebook and tutorial, we will fine-tune the [Mistral 7B](https://github.com/mistralai/mistral-src) model - which outperforms Llama 2 13B on all tested benchmarks - ***on your own data!***\n",
    "\n",
    "## Watch the accompanying video walk-through [here](https://youtu.be/kmkcNVvEz-k?si=Ogt1wRFNqYI6zXfw&t=1)!\n",
    "\n",
    "I did this for **just one dollar ($1)** on an 1x A10G 24GB from Brev.dev (instructions below).\n",
    "\n",
    "This tutorial will use QLoRA, a fine-tuning method that combines quantization and LoRA. For more information about what those are and how they work, see [this post](https://brev.dev/blog/how-qlora-works).\n",
    "\n",
    "In this notebook, we will load the large model in 4bit using `bitsandbytes` and use LoRA to train using the PEFT library from Hugging Face .\n",
    "\n",
    "Note that if you ever have trouble importing something from Huggingface, you may need to run `huggingface-cli login` in a shell. To open a shell in Jupyter Lab, click on 'Launcher' (or the '+' if it's not there) next to the notebook tab at the top of the screen. Under \"Other\", click \"Terminal\" and then run the command.\n",
    "\n",
    "### Help us make this tutorial better! Please provide feedback on the [Discord channel](https://discord.gg/RN2a436M73) or on [X](https://x.com/harperscarroll)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9TytWkb3m15"
   },
   "source": [
    "#### Before we begin: A note on OOM errors\n",
    "\n",
    "If you get an error like this: `OutOfMemoryError: CUDA out of memory`, tweak your parameters to make the model less computationally intensive. I will help guide you through that in this guide, and if you have any additional questions you can reach out on the [Discord channel](https://discord.gg/RN2a436M73) or on [X](https://x.com/harperscarroll).\n",
    "\n",
    "To re-try after you tweak your parameters, open a Terminal ('Launcher' or '+' in the nav bar above -> Other -> Terminal) and run the command `nvidia-smi`. Then find the process ID `PID` under `Processes` and run the command `kill [PID]`. You will need to re-start your notebook from the beginning. (There may be a better way to do this... if so please do let me know!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC-9m2yv3m18"
   },
   "source": [
    "## Let's begin!\n",
    "### 0. Preparing data\n",
    "\n",
    "Before you check out a GPU, prepare your dataset for loading and training.\n",
    "\n",
    "To prepare your dataset for loading, all you need are two `.jsonl` files structured something like this:\n",
    "```\n",
    "{\"input\": \"What color is the sky?\", \"output\": \"The sky is blue.\"}\n",
    "{\"input\": \"Where is the best place to get cloud GPUs?\", \"output\": \"Brev.dev\"}\n",
    "```\n",
    "If you choose to model your data as input/output pairs, you'll want to use something like the second `formatting_func` below, which will will combine all your features into one input string.\n",
    "\n",
    "As you can see below, I have `notes.jsonl` for my `train_dataset` and `notes_validation.jsonl` for my `eval_dataset`.\n",
    "\n",
    "I used Exporter, a free local-only app, to export my Apple Notes to `.txt` files, and then I wrote a script to process each note into one `.jsonl` file. Note that for this script, ChatGPT can help out a LOT if you tell it how your data is currently formatted, how you'd like it to be formatted, and ask it to write a script in a certain language you know well (for any debugging) to do so. I also broke up my journal entries so the training sample vector length was smaller (see the discussion on `max_length` and the data visualization below). I broke it into pieces so that contexts were encapsulated entirely, since I did want the model to understand context about my life. My data were ultimately formatted as:\n",
    "\n",
    "```json\n",
    "{\"note\": \"journal-entry-for-model-to-predict\"}\n",
    "{\"note\": \"journal-entry-for-model-to-predict-1\"}\n",
    "{\"note\": \"journal-entry-for-model-to-predict-2\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2CkxsA43m15"
   },
   "source": [
    "### 1. Instantiate GPU & Load Dataset\n",
    "\n",
    "I used a GPU and dev environment from [brev.dev](https://brev.dev). The whole thing cost me $1 using a 1xA10G 24GB. Click the badge below to get your preconfigured instance:\n",
    "\n",
    "[![](https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brevdeploynavy.svg)](https://console.brev.dev/environment/new?instance=A10G:g5.xlarge&diskStorage=256&name=mistral-finetune-own-data&file=https://github.com/brevdev/notebooks/raw/main/mistral-finetune-own-data.ipynb&python=3.10&cuda=12.0.1)\n",
    "\n",
    "A single A10G (as linked) with 24GB GPU Memory was enough for me. You may need more GPUs and/or Memory if your sequence max_length is larger than 512.\n",
    "\n",
    "Once you've checked out your machine and landed in your instance page, select the specs you'd like (I used **Python 3.10 and CUDA 12.0.1**; these should be preconfigured for you if you use the badge above) and click the \"Build\" button to build your verb container. Give this a few minutes.\n",
    "\n",
    "A few minutes after your model has started Running, click the 'Notebook' button on the top right of your screen once it illuminates (you may need to refresh the screen). You will be taken to a Jupyter Lab environment, where you can upload this Notebook.\n",
    "\n",
    "\n",
    "Note: You can connect your cloud credits (AWS or GCP) by clicking \"Org: \" on the top right, and in the panel that slides over, click \"Connect AWS\" or \"Connect GCP\" under \"Connect your cloud\" and follow the instructions linked to attach your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FuXIFTFapAMI",
    "outputId": "c8ced1ad-c7b3-44ba-807b-26d7d13906bc",
    "ExecuteTime": {
     "end_time": "2024-01-16T21:35:36.129435900Z",
     "start_time": "2024-01-16T21:34:41.121403500Z"
    }
   },
   "outputs": [],
   "source": [
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_json('../data/training_data.json', orient='records')\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train.to_json('furniture_data.jsonl', orient='records', lines=True)\n",
    "test.to_json('furniture_validation.jsonl', orient='records', lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:28:59.697226300Z",
     "start_time": "2024-01-16T21:28:59.647929300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s6f4z8EYmcJ6",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:33:57.748429900Z",
     "start_time": "2024-01-16T22:33:56.039910Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='furniture_data.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='furniture_validation.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05H5MIfjyRgc"
   },
   "source": [
    "### Accelerator\n",
    "\n",
    "Set up the Accelerator. I'm not sure if we really need this for a QLoRA given its [description](https://huggingface.co/docs/accelerate/v0.19.0/en/usage_guides/fsdp) (I have to read more about it) but it seems it can't hurt, and it's helpful to have the code for future reference. You can always comment out the accelerator if you want to try without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TEzYBadkyRgd",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:34:09.971271200Z",
     "start_time": "2024-01-16T22:34:07.911346800Z"
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9KNTJZkyRgn"
   },
   "source": [
    "\n",
    "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DDqUNyIoyRgo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  路路路路路路路路\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhw8JiOr3m18"
   },
   "source": [
    "### Formatting prompts\n",
    "Then create a `formatting_func` to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f-fJR0MlQiTD",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:34:13.944734500Z",
     "start_time": "2024-01-16T22:34:13.928735200Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"{example['prompt']} {example['expected_result']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sflV0DL2P64_"
   },
   "source": [
    "Here's another common one:\n",
    "\n",
    "```python\n",
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "    return text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shz8Xdv-yRgf"
   },
   "source": [
    "### 2. Load Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ-5idQwzvg-"
   },
   "source": [
    "Let's now load Mistral - mistralai/Mistral-7B-v0.1 - using 4-bit quantization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:34:18.781696700Z",
     "start_time": "2024-01-16T22:34:17.131265800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('notebooks/mistral-finetune-own-data.ipynb')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=121, Highest Compute Capability: 7.5.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary /home/aeolin/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n",
      "libcusparse.so.12: cannot open shared object file: No such file or directory\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://raw.githubusercontent.com/TimDettmers/bitsandbytes/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aeolin/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/utils/import_utils.py:1382\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1381\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1382\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1383\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/usr/lib/python3.9/importlib/__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:986\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:680\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:790\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:228\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/integrations/bitsandbytes.py:11\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_bitsandbytes_available():\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mbnb\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/__init__.py:6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# This source code is licensed under the MIT license found in the\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cuda_setup, utils, research\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_functions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      8\u001B[0m     MatmulLtState,\n\u001B[1;32m      9\u001B[0m     bmm_cublas,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m     matmul_4bit\n\u001B[1;32m     14\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/research/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_functions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      3\u001B[0m     switchback_bnb,\n\u001B[1;32m      4\u001B[0m     matmul_fp8_global,\n\u001B[1;32m      5\u001B[0m     matmul_fp8_mixed,\n\u001B[1;32m      6\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/research/nn/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/research/nn/modules.py:8\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mbnb\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GlobalOptimManager\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/optim/__init__.py:6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# This source code is licensed under the MIT license found in the\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m COMPILED_WITH_CUDA\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madagrad\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/bitsandbytes/cextension.py:20\u001B[0m\n\u001B[1;32m     19\u001B[0m     CUDASetup\u001B[38;5;241m.\u001B[39mget_instance()\u001B[38;5;241m.\u001B[39mprint_log_stack()\n\u001B[0;32m---> 20\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001B[39m\n\u001B[1;32m     22\u001B[0m \n\u001B[1;32m     23\u001B[0m \u001B[38;5;124m    python -m bitsandbytes\u001B[39m\n\u001B[1;32m     24\u001B[0m \n\u001B[1;32m     25\u001B[0m \u001B[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001B[39m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001B[39m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001B[39m\u001B[38;5;124m'''\u001B[39m)\n\u001B[1;32m     28\u001B[0m lib\u001B[38;5;241m.\u001B[39mcadam32bit_grad_fp32 \u001B[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 12\u001B[0m\n\u001B[1;32m      4\u001B[0m base_model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmistralai/Mistral-7B-v0.1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m bnb_config \u001B[38;5;241m=\u001B[39m BitsAndBytesConfig(\n\u001B[1;32m      6\u001B[0m     load_in_4bit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m     bnb_4bit_use_double_quant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      8\u001B[0m     bnb_4bit_quant_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnf4\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m     bnb_4bit_compute_dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mbfloat16\n\u001B[1;32m     10\u001B[0m )\n\u001B[0;32m---> 12\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_model_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbnb_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:566\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    565\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 566\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    572\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/modeling_utils.py:3476\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3473\u001B[0m     keep_in_fp32_modules \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   3475\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load_in_8bit \u001B[38;5;129;01mor\u001B[39;00m load_in_4bit:\n\u001B[0;32m-> 3476\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_keys_to_not_convert, replace_with_bnb_linear\n\u001B[1;32m   3478\u001B[0m     llm_int8_skip_modules \u001B[38;5;241m=\u001B[39m quantization_config\u001B[38;5;241m.\u001B[39mllm_int8_skip_modules\n\u001B[1;32m   3479\u001B[0m     load_in_8bit_fp32_cpu_offload \u001B[38;5;241m=\u001B[39m quantization_config\u001B[38;5;241m.\u001B[39mllm_int8_enable_fp32_cpu_offload\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1055\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/utils/import_utils.py:1372\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1370\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[1;32m   1371\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m-> 1372\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1373\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/utils/import_utils.py:1384\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1382\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1383\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1384\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1385\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1386\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1387\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjNdXolqyRgf"
   },
   "source": [
    "### 3. Tokenization\n",
    "\n",
    "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
    "\n",
    "\n",
    "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "outputId": "22ee95db-2974-4ab0-e0c7-444d04d3e838",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:14.332442800Z",
     "start_time": "2024-01-16T22:08:14.117702600Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnKLcq4yRgg"
   },
   "source": [
    "Reformat the prompt and tokenize each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S3iLAwLh3m19",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:17.658096400Z",
     "start_time": "2024-01-16T22:08:17.604001400Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ewk27p3m19"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BA8M9yfC3m19",
    "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:21.663377900Z",
     "start_time": "2024-01-16T22:08:20.649853600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1923\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBk4Qp_vyRgh"
   },
   "source": [
    "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
    "\n",
    "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMlw8h743m19"
   },
   "source": [
    "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "acINaViR3m19",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:25.091806600Z",
     "start_time": "2024-01-16T22:08:25.073576300Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 768 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "518d4f0b89bf4d57bf00d4c6d6e59eb5"
     ]
    },
    "id": "lTk-aTog3m19",
    "outputId": "4fb637b4-77a2-47c6-de7b-4fb620663dd7",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:26.532672500Z",
     "start_time": "2024-01-16T22:08:26.464454600Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQL796OayRgh"
   },
   "source": [
    "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OKHhvxK83m19",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:29.775029800Z",
     "start_time": "2024-01-16T22:08:29.701571600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 12628, 272, 2296, 2572, 13187, 28747, 28201, 28725, 261, 1438, 291, 846, 28725, 2081, 18256, 28725, 341, 20498, 28725, 25667, 28725, 21137, 28725, 854, 8137, 28725, 15912, 28725, 17538, 28725, 579, 17284, 28725, 2245, 3429, 28725, 3924, 404, 28723, 13, 28743, 21800, 653, 272, 2296, 20108, 2818, 356, 378, 28742, 28713, 10220, 304, 13623, 28747, 13, 8390, 9421, 395, 264, 8011, 1141, 477, 272, 2078, 13187, 28723, 13, 2963, 395, 418, 6349, 513, 272, 5447, 1235, 459, 4646, 778, 707, 302, 272, 2078, 13187, 28723, 13, 7522, 28747, 14722, 28940, 28796, 28754, 2192, 4844, 13, 2615, 512, 999, 13, 13, 7301, 28747, 13, 1014, 2401, 512, 999, 349, 275, 8722, 477, 7972, 18633, 304, 349, 11633, 354, 9882, 690, 7278, 28705, 28781, 28733, 28784, 905, 28723, 13, 13, 3260, 2401, 512, 999, 659, 264, 23420, 299, 5340, 304, 2870, 574, 7854, 2401, 1601, 1304, 4328, 354, 1560, 15048, 16423, 304, 8209, 28723, 13, 13, 28755, 770, 302, 28705, 28740, 28734, 28734, 28823, 18633, 28705, 30998, 264, 4229, 304, 26200, 3388, 369, 6755, 579, 810, 395, 1012, 14338, 28723, 13, 13, 8543, 272, 4118, 14722, 28940, 28796, 28754, 2192, 4844, 4076, 304, 11533, 22264, 442, 2918, 706, 2553, 764, 304, 2231, 12607, 354, 264, 14927, 28723, 13, 13, 9633, 28747, 28705, 25667, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6LRa2Zm3m19"
   },
   "source": [
    "Now all the samples should be the same length, `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "I55Yo3yy3m19",
    "outputId": "c87e344d-e0f3-4542-afcc-4e2025926d64",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:32.871677300Z",
     "start_time": "2024-01-16T22:08:31.382743300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1923\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP3R4enP3m19"
   },
   "source": [
    "### How does the base model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxbl4ACsyRgi"
   },
   "source": [
    "Optionally, you can check how Mistral does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gOxnx-cAyRgi",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:36.596500Z",
     "start_time": "2024-01-16T22:08:36.541462100Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\" Given the following possible categories: tables, beds, accessories, benches, sideboards, lighting, shelves, partitions, finishes, sofas, trolleys.\n",
    "Categorize the following Article based on it's Description and Title:\n",
    "Only respond with a category name from the given categories.\n",
    "Response with NONE if the article does not fit into any of the given categories.\n",
    "Title: MALM\n",
    "bed frame, high, w 2 storage boxes\n",
    "\n",
    "Description:\n",
    "Ample storage space is hidden neatly under the bed in 2 large drawers. Perfect for storing duvets, pillows and bed linen.\n",
    "\n",
    "The storage boxes are easy to roll out and in thanks to the castors on the base.\n",
    "\n",
    "MALM bed storage boxes work perfectly with MALM bed frame. They fit neatly into the space under the bed and will be flush against sides.\n",
    "\n",
    "You can sit up comfortably in bed thanks to the high headboard  just prop some pillows behind your back and you will have a comfortable place to read or watch TV.\n",
    "\n",
    "This versatile bed frame will look great with your choice of textiles and bedroom furniture.\n",
    "\n",
    "Adjustable bed sides allow you to use mattresses of different thicknesses.\n",
    "\n",
    "Category: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRhfq_Fa3m19"
   },
   "source": [
    "The `eval_prompt` I used was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pa6ux9ni3m19"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \" The following is a note by Eevee the Dog: # \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NidIuFXMyRgi",
    "outputId": "b1794b11-9a22-4b0a-e871-7df039ab59fc",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:42.468090400Z",
     "start_time": "2024-01-16T22:08:39.655068100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " given the following possible categories: tables, beds, accessories, benches, sideboards, lighting, shelves, partitions, finishes, sofas, trolleys.\n",
      "categorize the following article based on it's description and title:\n",
      "only respond with a category name from the given categories.\n",
      "response with none if the article does not fit into any of the given categories.\n",
      "title: malm\n",
      "bed frame, high, w 2 storage boxes\n",
      "\n",
      "description:\n",
      "ample storage space is hidden neatly under the bed in 2 large drawers. perfect for storing duvets, pillows and bed linen.\n",
      "\n",
      "the storage boxes are easy to roll out and in thanks to the castors on the base.\n",
      "\n",
      "malm bed storage boxes work perfectly with malm bed frame. they fit neatly into the space under the bed and will be flush against sides.\n",
      "\n",
      "you can sit up comfortably in bed thanks to the high headboard  just prop some pillows behind your back and you will have a comfortable place to read or watch tv.\n",
      "\n",
      "this versatile bed frame will look great with your choice of textiles and bedroom furniture.\n",
      "\n",
      "adjustable bed sides allow you to use mattresses of different thicknesses.\n",
      "\n",
      "category: \n",
      "beds\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCAWeCzZyRgi"
   },
   "source": [
    "Observe how the model does out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AapDoyfAyRgi"
   },
   "source": [
    "### 4. Set Up LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp2gMi1ZzGET"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a9EUEDAl0ss3",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:46.738492500Z",
     "start_time": "2024-01-16T22:08:46.649320400Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gkIcwsSU01EB",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:51.588553900Z",
     "start_time": "2024-01-16T22:08:51.577556800Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUYEpEK-yRgj"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XshGNsbxyRgj",
    "outputId": "c619b0e8-8516-4d4b-9abe-13eaa3f3b204",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:54.374156200Z",
     "start_time": "2024-01-16T22:08:54.319764100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mTLuQJyRgj"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:08:58.469397800Z",
     "start_time": "2024-01-16T22:08:57.520393700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_FHi_VLyRgn"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IaYMWak4yRgn",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:09:00.361509Z",
     "start_time": "2024-01-16T22:09:00.341352300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "### 5. Run Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEe0uWYSyRgo"
   },
   "source": [
    "I didn't have a lot of training samples: only about 200 total train/validation. I used 500 training steps, and I was fine with overfitting in this case. I found that the end product worked well. It took about 20 minutes on the 1x A10G 24GB.\n",
    "\n",
    "Overfitting is when the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. In most cases, this is not desired, but since I am just playing around with a model to generate outputs like my journal entries, I was fine with a moderate amount of overfitting.\n",
    "\n",
    "With that said, a note on training: you can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting, as described above. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir (`mistral-journal-finetune`) as your final model in step 6 below.\n",
    "\n",
    "If you're just doing something for fun like I did and are OK with overfitting, you can try different checkpoint versions with different degrees of overfitting.\n",
    "\n",
    "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c_L1131GyRgo",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:09:05.726051Z",
     "start_time": "2024-01-16T22:09:05.717540300Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yxSbpKQSLY6B",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:09:06.802831900Z",
     "start_time": "2024-01-16T22:09:06.790317400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jq0nX33BmfaC",
    "ExecuteTime": {
     "end_time": "2024-01-16T22:23:56.418597Z",
     "start_time": "2024-01-16T22:17:35.578817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/500 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 37\u001B[0m\n\u001B[1;32m      9\u001B[0m trainer \u001B[38;5;241m=\u001B[39m transformers\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[1;32m     10\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     11\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtokenized_train_dataset,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     33\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mtransformers\u001B[38;5;241m.\u001B[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m     34\u001B[0m )\n\u001B[1;32m     36\u001B[0m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:1537\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1535\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1537\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1538\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1539\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1540\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1541\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1542\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:1914\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1911\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[1;32m   1912\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m-> 1914\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1915\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1916\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:2268\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2266\u001B[0m         metrics\u001B[38;5;241m.\u001B[39mupdate(dataset_metrics)\n\u001B[1;32m   2267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2268\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[1;32m   2271\u001B[0m \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:3019\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3016\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3018\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3019\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3020\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3021\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3022\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[1;32m   3023\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[1;32m   3024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3025\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3026\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3027\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3029\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3030\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:3208\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3205\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m observed_batch_size\n\u001B[1;32m   3207\u001B[0m \u001B[38;5;66;03m# Prediction step\u001B[39;00m\n\u001B[0;32m-> 3208\u001B[0m loss, logits, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprediction_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3209\u001B[0m main_input_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain_input_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3210\u001B[0m inputs_decode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_input(inputs[main_input_name]) \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39minclude_inputs_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:3425\u001B[0m, in \u001B[0;36mTrainer.prediction_step\u001B[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001B[0m\n\u001B[1;32m   3423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_labels \u001B[38;5;129;01mor\u001B[39;00m loss_without_labels:\n\u001B[1;32m   3424\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3425\u001B[0m         loss, outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3426\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m   3428\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/trainer.py:2758\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2756\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2757\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2758\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2759\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2760\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/peft/peft_model.py:1073\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[1;32m   1062\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward in MPTForCausalLM does not support inputs_embeds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1063\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model(\n\u001B[1;32m   1064\u001B[0m             input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1065\u001B[0m             attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1070\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   1071\u001B[0m         )\n\u001B[0;32m-> 1073\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1074\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1084\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1086\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:103\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/accelerate/hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 165\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/transformers/models/mistral/modeling_mistral.py:1066\u001B[0m, in \u001B[0;36mMistralForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1053\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[1;32m   1054\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1055\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1062\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1063\u001B[0m )\n\u001B[1;32m   1065\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m-> 1066\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlm_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1067\u001B[0m logits \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m   1069\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/peft/tuners/lora/layer.py:364\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m    362\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_layer(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 364\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m active_adapter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactive_adapters:\n\u001B[1;32m    366\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m active_adapter \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlora_A\u001B[38;5;241m.\u001B[39mkeys():\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/accelerate/hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 165\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.virtualenvs/FurnitureLM/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"furniture-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        fp16=False,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "       # report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9rRmDCeQiTJ"
   },
   "source": [
    "I cleared the output of the cell above because I stopped the training early, and it produced a long, ugly error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D57XqcsyRgo"
   },
   "source": [
    "### 6. Drum Roll... Try the Trained Model!\n",
    "\n",
    "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`). \n",
    "\n",
    "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base model from the Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb8230fb86884aa6be318e2d03a88af2"
     ]
    },
    "id": "SKSnF016yRgp",
    "outputId": "bce5209d-90da-4117-c6ac-cda9f3cb3422"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8230fb86884aa6be318e2d03a88af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BxOhAiqyRgp"
   },
   "source": [
    "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwsiqhWuyRgp"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX39ibolyRgp"
   },
   "source": [
    "and run your inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUehsaVNyRgp"
   },
   "source": [
    "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better. I like playing with the repetition penalty (just little tweaks of .01-.05 at a time). THIS IS SO FUN. I'm obsessed wth this AI version of myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMkVNEUvyRgp",
    "outputId": "7d49d409-5dbe-4306-c1a4-9d87e3073397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The following is a note by Eevee the Dog, which doesn't share anything too personal: # \n",
      "Im grateful for my best friend coming to visit me. I know well have so much fun and our relationship will continue to flourish. We really are each others number one fan and its such a beautiful thing. She supports me in all that I do and celebrates my successes with joy and excitement. I am excited to show her around SF and take her to some of my favorite places. I hope she gets to meet some of my friends here as\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" The following is a note by Eevee the Dog, which doesn't share anything too personal: # \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCJnpZoayRgq"
   },
   "source": [
    "### Sweet... it worked! The fine-tuned model now prints out journal entries in my style!\n",
    "\n",
    "How funny to see it write like me as an angsty teenager, and honestly adult. I am obsessed. It knows who my friends are and talks about them, and covers the same topics I usually cover. It's really cool.\n",
    "\n",
    "That output is quite private but I wanted you to see an example run, so I tweaked the `eval_prompt` so that it explicitly wouldn't say anything too sensitive, haha.\n",
    "\n",
    "I hope you enjoyed this tutorial on fine-tuning Mistral on your own data. If you have any questions, feel free to reach out to me on [X](https://x.com/harperscarroll) or [Discord](https://discord.gg/RN2a436M73).\n",
    "\n",
    "                                                       "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
